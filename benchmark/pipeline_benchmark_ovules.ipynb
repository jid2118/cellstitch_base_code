{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from cellpose import models\n",
    "from cellpose import utils as cp_utils\n",
    "from cellstitch.pipeline import *\n",
    "from cellstitch.evaluation import *\n",
    "from cellstitch.utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ovules\" # or ovules_subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = [\"N_294_final_crop_ds2.npy\", \n",
    "                 \"N_435_final_crop_ds2.npy\",\n",
    "                 \"N_441_final_crop_ds2.npy\",\n",
    "                 \"N_511_final_crop_ds2.npy\",\n",
    "                 \"N_522_final_crop_ds2.npy\",\n",
    "                 \"N_590_final_crop_ds2.npy\",\n",
    "                 \"N_593_final_crop_ds2.npy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Benchmark\n",
    "\n",
    "Comparision between cellstitch (2D), cellpose3D (2.5D), plantseg (3D), cellstitch3D; using the same training set.\n",
    "\n",
    "### PlantSeg\n",
    "- First, created a plantseg virtual enviroment: \n",
    "    - `conda install -c conda-forge mamba` \n",
    "    - `mamba create -n plant-seg -c pytorch -c nvidia -c conda-forge -c lcerrone plantseg pytorch-cuda=11.7` \n",
    "- activate the environment: `conda activate plant-seg` \n",
    "- download the ovules test dataset: https://osf.io/uzq3w/ to `../DATA/<dataset>/plantseg_test/` \n",
    "- set the `path` in `config.yaml` to `../DATA/<dataset>/plantseg_test/` \n",
    "- perform segmentation with the `confocal_3D_unet_ovules_ds1x` by running `plantseg --config config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantseg_results_folder = \"../DATA/%s/plantseg_test/PreProcessing/confocal_3D_unet_ovules_ds1x/MultiCut\" % dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting N_294_final_crop_ds2.npy\n",
      "Starting N_435_final_crop_ds2.npy\n",
      "Starting N_441_final_crop_ds2.npy\n",
      "Starting N_511_final_crop_ds2.npy\n",
      "Starting N_522_final_crop_ds2.npy\n",
      "Starting N_590_final_crop_ds2.npy\n",
      "Starting N_593_final_crop_ds2.npy\n"
     ]
    }
   ],
   "source": [
    "for test_filename in test_filenames: \n",
    "    print(\"Starting %s\" % test_filename) \n",
    "    \n",
    "    with h5py.File(\"%s/%s_predictions_multicut.h5\" % (plantseg_results_folder, test_filename[:-4]), \"r\") as f:\n",
    "        plantseg = np.array(list(f['segmentation'])) \n",
    "        \n",
    "    plantseg[np.where(plantseg == 1)] = 0 # plantseg use 1 as labels\n",
    "    np.save(\"./results/%s/plantseg/%s\" % (dataset, test_filename), plantseg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train cellpose model from scratch\n",
    "First, need to prepare training data for cellpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = [\"N_404_ds2x.npy\", \n",
    "                  \"N_405_A_ds2x.npy\", \n",
    "                  \"N_405_B_ds2x.npy\", \n",
    "                  \"N_416_ds2x.npy\",\n",
    "                  \"N_422_ds2x.npy\",\n",
    "                  \"N_425_ds2x.npy\",\n",
    "                  \"N_428_ds2x.npy\",\n",
    "                  \"N_440_ds2x.npy\",\n",
    "                  \"N_445_ds2x.npy\",\n",
    "                  \"N_449_ds2x.npy\",\n",
    "                  \"N_450_ds2x.npy\", \n",
    "                  \"N_451_ds2x.npy\",\n",
    "                  \"N_454_ds2x.npy\",\n",
    "                  \"N_457_ds2x.npy\",\n",
    "                  \"N_458_ds2x.npy\",\n",
    "                  \"N_487_ds2x.npy\",\n",
    "                  \"N_509_ds2x.npy\",\n",
    "                  \"N_512_ds2x.npy\",\n",
    "                   \"N_517_ds2x.npy\",\n",
    "                  \"N_534_ds2x.npy\",\n",
    "                  \"N_535_ds2x.npy\",\n",
    "                  \"N_536_ds2x.npy\"]\n",
    "\n",
    "ovules_folder = \"../DATA/ovules\"\n",
    "cellpose_folder = \"../DATA/ovules/cellpose_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_filename in train_filenames: \n",
    "    img = np.load(\"%s/raw/%s\" % (ovules_folder, train_filename))\n",
    "    labels = np.load(\"%s/labels/%s\" % (ovules_folder, train_filename)) \n",
    "    depth = img.shape[0] \n",
    "    \n",
    "    for i in range(depth): \n",
    "        imageio.imwrite(\"%s/%s_%s.tif\" % (cellpose_folder, train_filename, i), img[i])\n",
    "        imageio.imwrite(\"%s/%s_%s_masks.tif\" % (cellpose_folder, train_filename, i), labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m cellpose --train --dir ../DATA/ovules/cellpose_train --pretrained_model None --n_epochs 100  --verbose` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cellpose3d results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../DATA/ovules/cellpose_train/models/cellpose_residual_on_style_on_concatenation_off_cellpose_train_2023_05_08_09_31_06.231473'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_threshold = 1\n",
    "model = models.CellposeModel(gpu=True, pretrained_model=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting N_294_final_crop_ds2.npy\n",
      "Starting N_435_final_crop_ds2.npy\n",
      "Starting N_441_final_crop_ds2.npy\n",
      "Starting N_511_final_crop_ds2.npy\n",
      "Starting N_522_final_crop_ds2.npy\n",
      "Starting N_590_final_crop_ds2.npy\n",
      "Starting N_593_final_crop_ds2.npy\n"
     ]
    }
   ],
   "source": [
    "for test_filename in test_filenames: \n",
    "    print(\"Starting %s\" % test_filename)\n",
    "    img = np.load(\"../DATA/%s/raw/%s\" % (dataset, test_filename)) \n",
    "    masks, _, _ = model.eval(img, do_3D=True, flow_threshold=flow_threshold, channels = [0,0]) \n",
    "    np.save(\"./results/%s/cellpose3d/%s\" % (dataset, test_filename), masks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cellpose2d results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting N_294_final_crop_ds2.npy\n",
      "Starting N_435_final_crop_ds2.npy\n",
      "Starting N_441_final_crop_ds2.npy\n",
      "Starting N_511_final_crop_ds2.npy\n",
      "Starting N_522_final_crop_ds2.npy\n",
      "Starting N_590_final_crop_ds2.npy\n",
      "Starting N_593_final_crop_ds2.npy\n"
     ]
    }
   ],
   "source": [
    "for test_filename in test_filenames: \n",
    "    print(\"Starting %s\" % test_filename)\n",
    "    img = np.load(\"../DATA/%s/raw/%s\" % (dataset, test_filename)) \n",
    "    masks, _, _ = model.eval(list(img), do_3D=False, flow_threshold=flow_threshold, channels = [0,0])\n",
    "    masks = cp_utils.stitch3D(np.array(masks))\n",
    "    \n",
    "    np.save(\"./results/%s/cellpose2d/%s\" % (dataset, test_filename), masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cellstitch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting N_294_final_crop_ds2.npy\n",
      "Starting N_435_final_crop_ds2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n",
      "WARNING: no mask pixels found\n",
      "WARNING: no mask pixels found\n",
      "WARNING: no mask pixels found\n",
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting N_441_final_crop_ds2.npy\n",
      "Starting N_511_final_crop_ds2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting N_522_final_crop_ds2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n",
      "WARNING: no mask pixels found\n",
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting N_590_final_crop_ds2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n",
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting N_593_final_crop_ds2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    }
   ],
   "source": [
    "for test_filename in test_filenames: \n",
    "    print(\"Starting %s\" % test_filename)\n",
    "    img = np.load(\"../DATA/%s/raw/%s\" % (dataset, test_filename)) \n",
    "    \n",
    "    cellstitch, _, _ = model.eval(list(img), flow_threshold=flow_threshold, channels = [0,0])\n",
    "    cellstitch = np.array(cellstitch)\n",
    "\n",
    "    yz_masks, _, _ = model.eval(list(img.transpose(1,0,2)), flow_threshold=flow_threshold, channels = [0,0])\n",
    "    yz_masks = np.array(yz_masks).transpose(1,0,2)\n",
    "\n",
    "    xz_masks, _, _ = model.eval(list(img.transpose(2,1,0)), flow_threshold=flow_threshold, channels = [0,0])\n",
    "    xz_masks = np.array(xz_masks).transpose(2,1,0)\n",
    "\n",
    "    full_stitch(cellstitch, yz_masks, xz_masks)\n",
    "    \n",
    "    np.save(\"./results/%s/cellstitch/%s\" % (dataset, test_filename), cellstitch) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting plantseg\n",
      "Starting N_294_final_crop_ds2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yining/anaconda3/envs/segmentation/lib/python3.8/site-packages/cellpose/metrics.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iou = overlap / (n_pixels_pred + n_pixels_true - overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting N_435_final_crop_ds2.npy\n",
      "Starting N_441_final_crop_ds2.npy\n",
      "Starting N_511_final_crop_ds2.npy\n",
      "Starting N_522_final_crop_ds2.npy\n",
      "Starting N_590_final_crop_ds2.npy\n",
      "Starting N_593_final_crop_ds2.npy\n"
     ]
    }
   ],
   "source": [
    "methods = [\"plantseg\"]\n",
    "\n",
    "for method in methods: \n",
    "    print(\"Starting %s\" % method) \n",
    "    \n",
    "    data = []\n",
    "    for filename in test_filenames:\n",
    "        print(\"Starting %s\" % filename)\n",
    "        labels = np.load('../DATA/%s/labels/%s' % (dataset, filename)) \n",
    "        masks = np.load(\"./results/%s/%s/%s\" % (dataset, method, filename))\n",
    "        \n",
    "        ap25, _, _, _ = average_precision(labels, masks, 0.25)\n",
    "        ap50, tp, fp, fn = average_precision(labels, masks, 0.5)\n",
    "        ap75, _, _, _ = average_precision(labels, masks, 0.75) \n",
    "        \n",
    "        if (tp + fp) != 0: \n",
    "            precision = tp / (tp + fp)\n",
    "        else: \n",
    "            precision = 0\n",
    "            \n",
    "        if tp + fp != 0: \n",
    "            recall = tp / (tp + fn)\n",
    "        else: \n",
    "            precision = 0\n",
    "\n",
    "        row = [ \n",
    "            filename, \n",
    "            ap25,\n",
    "            ap50,\n",
    "            ap75,\n",
    "            tp, \n",
    "            fp, \n",
    "            fn, \n",
    "            precision,\n",
    "            recall\n",
    "        ]\n",
    "\n",
    "        data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        \"filename\",\n",
    "        \"ap25\", \n",
    "        \"ap50\",\n",
    "        \"ap75\", \n",
    "        \"tp\", \n",
    "        \"fp\", \n",
    "        \"fn\",\n",
    "        \"precision\",\n",
    "        \"recall\"\n",
    "    ])\n",
    "\n",
    "    df.to_csv(\"./results/%s/%s.csv\" % (dataset, method), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation-aeolus",
   "language": "python",
   "name": "segmentation-aeolus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
